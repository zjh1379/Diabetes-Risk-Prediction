{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqXpWV2pzMw0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "All the imports needed throughout the project, the data is mounted onto the notebook via google drive mounting.\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
        "multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# !ls \"/content/drive/My Drive/Foundations AI Final Project Data/\"\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NHANES Data Processing\n",
        "\"\"\"\n",
        "\n",
        "xpt_2023_demographic = '/content/drive/My Drive/Foundations AI Final Project Data/2023_demographic.xpt'\n",
        "xpt_2020_demographic = '/content/drive/My Drive/Foundations AI Final Project Data/2020_demographic.xpt'\n",
        "xpt_2016_demographic = '/content/drive/My Drive/Foundations AI Final Project Data/2016_demographic.xpt'\n",
        "items1 = [\"RIAGENDR\", \"RIDAGEYR\", \"RIDRETH1\"]\n",
        "\n",
        "\n",
        "xpt_2023_diabetes = '/content/drive/My Drive/Foundations AI Final Project Data/2023_diabetes.xpt'\n",
        "xpt_2020_diabetes = '/content/drive/My Drive/Foundations AI Final Project Data/2020_diabetes.xpt'\n",
        "xpt_2016_diabetes = '/content/drive/My Drive/Foundations AI Final Project Data/2016_diabetes.xpt'\n",
        "items2 = [\"DIQ010\"]\n",
        "\n",
        "xpt_2023_body = '/content/drive/My Drive/Foundations AI Final Project Data/2023_body.xpt'\n",
        "xpt_2020_body = '/content/drive/My Drive/Foundations AI Final Project Data/2020_body.xpt'\n",
        "xpt_2016_body = '/content/drive/My Drive/Foundations AI Final Project Data/2016_body.xpt'\n",
        "items3 = [\"BMXWT\", \"BMXHT\", \"BMXBMI\", \"BMXWAIST\", \"BMXARMC\"]\n",
        "\n",
        "xpt_2023_glyco = '/content/drive/My Drive/Foundations AI Final Project Data/2023_glyco.xpt'\n",
        "xpt_2020_glyco = '/content/drive/My Drive/Foundations AI Final Project Data/2020_glyco.xpt'\n",
        "xpt_2016_glyco = '/content/drive/My Drive/Foundations AI Final Project Data/2016_glyco.xpt'\n",
        "items4 = [\"LBXGH\"]\n",
        "\n",
        "xpt_2023_glucose = '/content/drive/My Drive/Foundations AI Final Project Data/2023_glucose.xpt'\n",
        "xpt_2020_glucose = '/content/drive/My Drive/Foundations AI Final Project Data/2020_glucose.xpt'\n",
        "xpt_2016_glucose = '/content/drive/My Drive/Foundations AI Final Project Data/2016_glucose.xpt'\n",
        "items5 = [\"LBXGLU\"]\n",
        "\n",
        "xpt_2023_insulin = '/content/drive/My Drive/Foundations AI Final Project Data/2023_insulin.xpt'\n",
        "xpt_2020_insulin = '/content/drive/My Drive/Foundations AI Final Project Data/2020_insulin.xpt'\n",
        "xpt_2016_insulin = '/content/drive/My Drive/Foundations AI Final Project Data/2016_insulin.xpt'\n",
        "items6 = [\"LBXIN\"]\n",
        "\n",
        "xpt_2023_dietary = '/content/drive/My Drive/Foundations AI Final Project Data/2023_dietary.xpt'\n",
        "xpt_2020_dietary = '/content/drive/My Drive/Foundations AI Final Project Data/2020_dietary.xpt'\n",
        "xpt_2016_dietary = '/content/drive/My Drive/Foundations AI Final Project Data/2016_dietary.xpt'\n",
        "items7 = [\"DRQSPREP\", \"DR1TSUGR\", \"DR1TCARB\", \"DR1TTFAT\"]\n",
        "\n",
        "xpt_2023_bp_c = '/content/drive/My Drive/Foundations AI Final Project Data/2023_bp_c.xpt'\n",
        "xpt_2020_bp_c = '/content/drive/My Drive/Foundations AI Final Project Data/2020_bp_c.xpt'\n",
        "xpt_2016_bp_c = '/content/drive/My Drive/Foundations AI Final Project Data/2016_bp_c.xpt'\n",
        "items8 = [\"BPQ020\", \"BPQ080\"]\n",
        "\n",
        "xpt_2023_hospital = '/content/drive/My Drive/Foundations AI Final Project Data/2023_hospital.xpt'\n",
        "xpt_2020_hospital = '/content/drive/My Drive/Foundations AI Final Project Data/2020_hospital.xpt'\n",
        "xpt_2016_hospital = '/content/drive/My Drive/Foundations AI Final Project Data/2016_hospital.xpt'\n",
        "items9 = [\"HUQ010\"]\n",
        "\n",
        "xpt_2023_smoke = '/content/drive/My Drive/Foundations AI Final Project Data/2023_smoke.xpt'\n",
        "xpt_2020_smoke = '/content/drive/My Drive/Foundations AI Final Project Data/2020_smoke.xpt'\n",
        "xpt_2016_smoke = '/content/drive/My Drive/Foundations AI Final Project Data/2016_smoke.xpt'\n",
        "items10 = [\"SMD460\"]\n",
        "\n",
        "# SEQN - Respondent sequence number\n",
        "# DIQ010 - Have diabetes [1 yes, 2 no]\n",
        "# RIAGENDR - Gender\n",
        "# RIDAGEYR - Age\n",
        "# RIDRETH1 - Ethinicity [C]\n",
        "# BMXWT - Weight kg\n",
        "# BMXHT - Height cm\n",
        "# BMXBMI - BMI\n",
        "# BMXWAIST - Waist circumference cm\n",
        "# BMXARMC - Arm circumference cm\n",
        "# LBXGH - Glycohemoglobin (%)\n",
        "# LBXGLU - Fasting Glucose (mg/dL)\n",
        "# LBXIN - Insulin (uU/mL)\n",
        "# DRQSPREP - Salt used in preparation [1 never ~ 4 very often, 9 donotknow, . missing]\n",
        "# DR1TSUGR - Total sugars (gm)\n",
        "# DR1TCARB - Carbohydrate (gm)\n",
        "# DR1TTFAT - Total fat (gm)\n",
        "# BPQ020 - Have high blood pressure [1 yes, 2 no]\n",
        "# BPQ080 = Have high cholesterol [1 yes, 2 no]\n",
        "# HUQ010 - General health condition [1 ~ 5, 1 is best]\n",
        "# SMD460 - Number of people who live here smoke tobacco [0, 1, 2]\n",
        "\n",
        "\n",
        "\n",
        "files = {\n",
        "    \"demographic\": [\"RIAGENDR\", \"RIDAGEYR\", \"RIDRETH1\"],\n",
        "    \"body\": [\"BMXWT\", \"BMXHT\", \"BMXBMI\", \"BMXWAIST\", \"BMXARMC\"],\n",
        "    \"glyco\": [\"LBXGH\"],\n",
        "    \"glucose\": [\"LBXGLU\"],\n",
        "    \"insulin\": [\"LBXIN\"],\n",
        "    \"dietary\": [\"DRQSPREP\", \"DR1TSUGR\", \"DR1TCARB\", \"DR1TTFAT\"],\n",
        "    \"bp_c\": [\"BPQ020\", \"BPQ080\"],\n",
        "    \"hospital\": [\"HUQ010\"],\n",
        "    \"smoke\": [\"SMD460\"]\n",
        "}\n",
        "\n",
        "df_2016 = pd.read_sas(xpt_2016_diabetes, format='xport')[['SEQN','DIQ010']]\n",
        "df_2020 = pd.read_sas(xpt_2020_diabetes, format='xport')[['SEQN','DIQ010']]\n",
        "df_2023 = pd.read_sas(xpt_2023_diabetes, format='xport')[['SEQN','DIQ010']]\n",
        "\n",
        "# There shows no duplicates in the SEQN numbers\n",
        "df_persons = pd.concat([df_2016, df_2020, df_2023], ignore_index=True)\n",
        "df_persons = df_persons[df_persons[\"DIQ010\"].isin([1, 2])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A9SuBFm-zfJz",
        "outputId": "3d316ab0-646d-4ea3-d892-efc0419da64e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNHANES Data Processing\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the rows and columns from the other files\n",
        "\n",
        "file_base_path = \"/content/drive/My Drive/Foundations AI Final Project Data/\"\n",
        "df_main = df_persons.set_index(\"SEQN\")\n",
        "\n",
        "for year in [\"2016\",\"2020\",\"2023\"]:\n",
        "    for name, cols in files.items():\n",
        "        path = f\"{file_base_path}{year}_{name}.xpt\"\n",
        "        df_year = (\n",
        "            pd.read_sas(path, format=\"xport\")\n",
        "              .set_index(\"SEQN\")[cols]\n",
        "              .reindex(df_main.index)\n",
        "        )\n",
        "        for c in cols:\n",
        "            if c in df_main.columns:\n",
        "                df_main[c] = df_main[c].fillna(df_year[c])\n",
        "            else:\n",
        "                df_main[c] = df_year[c]\n",
        "\n",
        "df_main = df_main.reset_index()\n",
        "\n",
        "\n",
        "# Target encoding\n",
        "# This must be kept in the data frame init cell as repeated runs change the data\n",
        "\n",
        "df_main['DIQ010'] = (df_main['DIQ010'] == 1).astype(int)\n",
        "df_main['RIAGENDR'] = (df_main['RIAGENDR'] == 1).astype(int)\n",
        "df_main['RIDRETH1'] = df_main.groupby('RIDRETH1')['DIQ010'].transform('mean')\n",
        "df_main['BPQ020'] = (df_main['BPQ020'] == 1).astype(int)\n",
        "df_main['BPQ080'] = (df_main['BPQ080'] == 1).astype(int)\n",
        "\n",
        "col = df_main['DRQSPREP'].where(df_main['DRQSPREP'].between(1,4))\n",
        "df_main['DRQSPREP'] = (col.fillna(col.median()) - 1) / 3\n",
        "\n",
        "col = df_main['HUQ010'].where(df_main['HUQ010'].between(1,5))\n",
        "df_main['HUQ010'] = (col.fillna(5 - col.median())) / 4\n",
        "\n",
        "cols = ['RIDAGEYR', 'BMXWT', 'BMXHT', 'BMXBMI', 'BMXWAIST', 'BMXARMC', 'LBXGH', 'LBXGLU', 'LBXIN', 'DR1TSUGR', 'DR1TCARB', 'DR1TTFAT']\n",
        "df_main[cols] = df_main[cols].apply(lambda x: (x.fillna(x.median()) - x.min()) / (x.max() - x.min()))\n",
        "\n",
        "rounded = df_main['SMD460'].round()\n",
        "med = rounded.median()\n",
        "df_main['SMD460'] = rounded.fillna(med).astype('Int64')\n",
        "\n",
        "\n",
        "df_main.drop('SEQN', axis=1, inplace=True)\n",
        "df_main.rename(columns={'DIQ010': 'Diabetes_binary'}, inplace=True)\n",
        "\n",
        "n_pos = df_main['Diabetes_binary'].eq(1).sum()\n",
        "df_pos = df_main[df_main['Diabetes_binary'] == 1]\n",
        "df_neg_sample = df_main[df_main['Diabetes_binary'] == 0].sample(n=n_pos, random_state=42)\n",
        "df_balanced = pd.concat([df_pos, df_neg_sample]).sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "EgKBxanBzoQZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Kaggle data processing\n",
        "\"\"\"\n",
        "\n",
        "kaggle_data_path = \"/content/drive/My Drive/Foundations AI Final Project Data/kaggle_diabetes_data.csv\"\n",
        "kaggle_data_df = pd.read_csv(kaggle_data_path)\n",
        "\n",
        "for col in kaggle_data_df.columns:\n",
        "    max_val = kaggle_data_df[col].max()\n",
        "    if max_val > 1:\n",
        "        kaggle_data_df[col] = kaggle_data_df[col] / max_val"
      ],
      "metadata": {
        "id": "tOMGx_IZzwWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The base GA-NN training algorithm\n",
        "\"\"\"\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(\n",
        "            self,\n",
        "            data = kaggle_data_df,\n",
        "            n_features = 21,\n",
        "            pop_size = 24,\n",
        "            generations = 120,\n",
        "            fitness_threshold = 0.9,\n",
        "            crossover_rate = 0.8,\n",
        "            mutation_rate = 0.1,\n",
        "            epoch_limit = 8,\n",
        "            batch_size = 3200,\n",
        "            learning_rate = 0.01\n",
        "            ):\n",
        "\n",
        "        self.data = data\n",
        "        self.n_features = n_features\n",
        "        self.pop_size = pop_size\n",
        "        self.generations = generations\n",
        "        self.fitness_threshold = fitness_threshold\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "\n",
        "        self.epoch_limit = epoch_limit\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.population = self.initialize_population()\n",
        "        self.pop_fitness = []\n",
        "\n",
        "    def initialize_population(self):\n",
        "        pop = np.random.randint(0, 2, (self.pop_size-1, self.n_features))\n",
        "        full_ind = np.ones((1, self.n_features), dtype=int)\n",
        "        return np.concatenate((pop, full_ind), axis=0)\n",
        "\n",
        "    def selection(self, fitnesses):\n",
        "        chosen = []\n",
        "        for _ in range(self.pop_size):\n",
        "            i, j = random.sample(range(self.pop_size), 2)\n",
        "            if fitnesses[i] > fitnesses[j]:\n",
        "                chosen.append(self.population[i].copy())\n",
        "            else:\n",
        "                chosen.append(self.population[j].copy())\n",
        "        return np.array(chosen)\n",
        "\n",
        "    def crossover(self, p1, p2):\n",
        "        i = random.randint(1, self.n_features - 1)\n",
        "        c1 = np.concatenate((p1[:i], p2[i:]))\n",
        "        c2 = np.concatenate((p2[:i], p1[i:]))\n",
        "        return c1, c2\n",
        "\n",
        "    def mutate(self, indv):\n",
        "        for i in range(self.n_features):\n",
        "            if random.random() < self.mutation_rate:\n",
        "                # flips the boolean indicator value\n",
        "                indv[i] = 1 - indv[i]\n",
        "        return indv\n",
        "\n",
        "    def next_gen(self):\n",
        "        self.evaluate_population()\n",
        "        chosen = self.selection(self.pop_fitness)\n",
        "        new_pop = []\n",
        "\n",
        "        for i in range(0, self.pop_size, 2):\n",
        "            p1 = chosen[i]\n",
        "            p2 = chosen[ i+1 if i+1 < self.pop_size else 0 ]\n",
        "\n",
        "            if random.random() < self.crossover_rate:\n",
        "                c1, c2 = self.crossover(p1, p2)\n",
        "            else:\n",
        "                c1, c2 = p1.copy(), p2.copy()\n",
        "\n",
        "            new_pop.append(self.mutate(c1))\n",
        "            new_pop.append(self.mutate(c2))\n",
        "        # prevents population size increase due to even number of children despite odd population size\n",
        "        self.population = np.array(new_pop[:self.pop_size])\n",
        "\n",
        "    def evolve(self):\n",
        "        for gen in tqdm(range(self.generations), desc='GA Generations'):\n",
        "            self.next_gen()\n",
        "            print(\"Generation\", gen, \"Best fit:\", max(self.pop_fitness))\n",
        "        self.evaluate_population()\n",
        "        print(\"Final fitness\", self.pop_fitness)\n",
        "        print(\"Best indv\", self.population[np.argmax(self.pop_fitness)])\n",
        "\n",
        "\n",
        "    def evaluate_gene(self, gene):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        selected_features = np.where(gene == 1)[0]\n",
        "        if len(selected_features) < 5:\n",
        "            return 0.0\n",
        "\n",
        "        data_sample = self.data.sample(n=30000)\n",
        "        X = data_sample.drop(\"Diabetes_binary\", axis=1).values\n",
        "        y = data_sample[\"Diabetes_binary\"].values\n",
        "        X_selected = X[:, selected_features]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(X_train_tensor.shape[1], 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid()\n",
        "        ).to(device)\n",
        "        criterion = nn.BCELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        for epoch in tqdm(range(self.epoch_limit), desc='Training NN', leave=False, position=0):\n",
        "            model.train()\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                preds = model(X_batch)\n",
        "                loss = criterion(preds, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(X_test_tensor)\n",
        "            preds = (outputs > 0.5).float()\n",
        "            accuracy = (preds == y_test_tensor).sum().item() / y_test_tensor.shape[0]\n",
        "\n",
        "            # Compute AUC score:\n",
        "            pred_probs = outputs.detach().cpu().numpy()\n",
        "            y_true = y_test_tensor.detach().cpu().numpy()\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, pred_probs)\n",
        "            except Exception as e:\n",
        "                # Fallback if AUC calculation fails (e.g., if one class is missing)\n",
        "                auc = accuracy\n",
        "\n",
        "        \"\"\"\n",
        "        This version utilized mainly auc and acc metrics and various ways to combine them\n",
        "        \"\"\"\n",
        "\n",
        "        weight_acc = 1.1\n",
        "        weight_auc = 0.9\n",
        "        composite = (accuracy ** weight_acc) * (auc ** weight_auc)\n",
        "\n",
        "        penalty_weight = 0.1\n",
        "        penalty = penalty_weight * ((len(selected_features) / self.n_features) ** 2)\n",
        "\n",
        "        final_fitness = composite - penalty\n",
        "        return final_fitness\n",
        "\n",
        "\n",
        "    def evaluate_population(self):\n",
        "        # Use ProcessPoolExecutor.map, which returns results in order of the input.\n",
        "        with ThreadPoolExecutor(max_workers=12) as executor:\n",
        "        # The executor.map call will preserve order.\n",
        "            self.pop_fitness = list(tqdm(executor.map(self.evaluate_gene, self.population),\n",
        "                                        total=len(self.population),\n",
        "                                        desc=\"Evaluating NNs\",\n",
        "                                        leave=False,\n",
        "                                        position=0))"
      ],
      "metadata": {
        "id": "70-pII1Bz6EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneticAlgorithm_v2:\n",
        "    def __init__(\n",
        "            self,\n",
        "            data,\n",
        "            n_features = 21,\n",
        "            pop_size = 32,\n",
        "            generations = 200,\n",
        "            fitness_threshold = 0.9,\n",
        "            crossover_rate = 0.5,\n",
        "            mutation_rate = 0.1,\n",
        "            epoch_limit = 8,\n",
        "            batch_size = 3200,\n",
        "            learning_rate = 0.01,\n",
        "            children_count = 8,\n",
        "            ):\n",
        "\n",
        "        \"\"\"\n",
        "        To run the cooperative coevalutation version, reduce the n_features to the gene size, and add adjustments before the NN training to align the features\n",
        "        \"\"\"\n",
        "\n",
        "        self.data = data\n",
        "        self.n_features = n_features\n",
        "        self.pop_size = pop_size\n",
        "        self.generations = generations\n",
        "        self.fitness_threshold = fitness_threshold\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "\n",
        "        self.epoch_limit = epoch_limit\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.population = self.initialize_population()\n",
        "        self.pop_fitness = []\n",
        "\n",
        "        self.children_count = children_count\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def initialize_population(self):\n",
        "        pop = np.random.randint(0, 2, (self.pop_size-1, self.n_features))\n",
        "        full_ind = np.ones((1, self.n_features), dtype=int)\n",
        "        return np.concatenate((pop, full_ind), axis=0)\n",
        "\n",
        "    def selection(self, fitnesses):\n",
        "        scaled = np.array(fitnesses) - np.min(fitnesses) + 1e-6\n",
        "        probs  = scaled / scaled.sum()\n",
        "        idxs   = np.random.choice(self.pop_size, size=2, p=probs)\n",
        "        return self.population[idxs].copy()\n",
        "\n",
        "    def crossover(self, p1, p2):\n",
        "        c1, c2 = p1.copy(), p2.copy()\n",
        "        for i in range(self.n_features):\n",
        "            if random.random() > self.crossover_rate:\n",
        "                c1[i], c2[i] = c2[i], c1[i]\n",
        "        return c1, c2\n",
        "\n",
        "    def mutate(self, indv):\n",
        "        for i in range(self.n_features):\n",
        "            if random.random() < self.mutation_rate:\n",
        "                # flips the boolean indicator value\n",
        "                indv[i] = 1 - indv[i]\n",
        "        return indv\n",
        "\n",
        "    def next_gen(self):\n",
        "        children = []\n",
        "        for _ in range(self.children_count // 2):\n",
        "            p1, p2 = self.selection(self.pop_fitness)\n",
        "            c1, c2 = self.crossover(p1, p2)\n",
        "            children.append(self.mutate(c1))\n",
        "            children.append(self.mutate(c2))\n",
        "\n",
        "        combined_population = np.concatenate((self.population, children), axis=0)\n",
        "        new_fitness = self.evaluate_group(children)\n",
        "        combined_fitness = np.concatenate((self.pop_fitness, new_fitness), axis=0)\n",
        "\n",
        "        # Select the best individuals from the combined population\n",
        "        best_indices = np.argsort(combined_fitness)[-self.pop_size:]\n",
        "\n",
        "        # Replace the population with the best individuals\n",
        "        self.population = combined_population[best_indices]\n",
        "        self.pop_fitness = combined_fitness[best_indices]\n",
        "\n",
        "    def evolve(self):\n",
        "        self.evaluate_population()\n",
        "        for gen in tqdm(range(self.generations), desc='GA Generations'):\n",
        "            self.next_gen()\n",
        "            # Find index of best fitness in current population\n",
        "            best_idx = int(np.argmax(self.pop_fitness))\n",
        "            best_fit = self.pop_fitness[best_idx]\n",
        "            best_ind = self.population[best_idx]\n",
        "            # Print both fitness and the binary vector of the best individual\n",
        "            print(f\"Generation {gen} | Best fit: {best_fit:.4f} | Best indv: {best_ind}\")\n",
        "        # Final summary\n",
        "        final_best_idx = int(np.argmax(self.pop_fitness))\n",
        "        print(\"Final fitness:\", self.pop_fitness)\n",
        "        print(\"Best individual overall:\", self.population[final_best_idx])\n",
        "\n",
        "\n",
        "    def evaluate_gene(self, gene):\n",
        "        selected_features = np.where(gene == 1)[0]\n",
        "        if len(selected_features) < 4:\n",
        "            return 0.0\n",
        "\n",
        "        X = self.data.drop(\"Diabetes_binary\", axis=1).to_numpy(dtype=np.float32)\n",
        "        y = self.data[\"Diabetes_binary\"].to_numpy(dtype=np.float32)\n",
        "        X_selected = X[:, selected_features]\n",
        "        X_train_all, X_test, y_train_all, y_test = train_test_split(\n",
        "            X_selected, y, test_size=0.3, random_state=42\n",
        "        )\n",
        "\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(self.device, non_blocking=True)\n",
        "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(self.device, non_blocking=True)\n",
        "\n",
        "\n",
        "        kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "        fold_scores = []\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_all), 1):\n",
        "            X_train, y_train = X_train_all[train_idx], y_train_all[train_idx]\n",
        "            X_val,   y_val   = X_train_all[val_idx],   y_train_all[val_idx]\n",
        "\n",
        "            idx = np.random.choice(len(X_train), size=4096, replace=False)\n",
        "            X_train, y_train = X_train[idx], y_train[idx]\n",
        "\n",
        "            # CPU tensors → DataLoader\n",
        "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "            y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "            X_val_tensor   = torch.tensor(X_val,   dtype=torch.float32).to(self.device, non_blocking=True)\n",
        "            y_val_tensor   = torch.tensor(y_val,   dtype=torch.float32).unsqueeze(1).to(self.device, non_blocking=True)\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                TensorDataset(X_train_tensor, y_train_tensor),\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=4,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "            model = nn.Sequential(\n",
        "                nn.Linear(X_train_tensor.shape[1], 16),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.25),\n",
        "                nn.Linear(16, 1)\n",
        "            ).to(self.device)\n",
        "\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=self.learning_rate)\n",
        "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "            scaler = GradScaler()\n",
        "\n",
        "            for epoch in tqdm(range(self.epoch_limit), desc='Training NN', leave=False, position=0):\n",
        "                t0 = time.time()\n",
        "\n",
        "                # — TRAINING —\n",
        "                model.train()\n",
        "                for Xb, yb in train_loader:\n",
        "                    Xb, yb = Xb.to(self.device, non_blocking=True), yb.to(self.device, non_blocking=True)\n",
        "                    optimizer.zero_grad()\n",
        "                    with autocast(device_type='cuda'):\n",
        "                        logits = model(Xb)\n",
        "                        loss   = criterion(logits, yb)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                # — VALIDATE (use X_val) —\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_out  = model(X_val_tensor)\n",
        "                    val_loss = criterion(val_out, y_val_tensor)\n",
        "                scheduler.step(val_loss)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_logits = model(X_test_tensor)\n",
        "                test_probs  = torch.sigmoid(test_logits)\n",
        "\n",
        "                mse = ((test_probs - y_test_tensor)**2).mean().item()\n",
        "                preds    = (test_probs > 0.5).float()\n",
        "                acc      = (preds == y_test_tensor).float().mean().item()\n",
        "                auc      = roc_auc_score(\n",
        "                            y_test_tensor.cpu().numpy(),\n",
        "                            test_probs.cpu().numpy()\n",
        "                        )\n",
        "\n",
        "            penalty = 0\n",
        "            if np.sum(gene) > 10:\n",
        "                penalty = ((np.sum(gene) - 10) / (self.n_features - 10)) * 0.05\n",
        "            fold_scores.append(0.4 * acc + 0.4 * auc + 0.2 * (1 - mse) - penalty)\n",
        "\n",
        "        return float(np.mean(fold_scores))\n",
        "\n",
        "    \"\"\"\n",
        "    Parallel COmputing setup for faster training\n",
        "    \"\"\"\n",
        "\n",
        "    def evaluate_group(self, group):\n",
        "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "            # Execute evaluate_gene in parallel for the group (which can be the children)\n",
        "            return list(tqdm(executor.map(self.evaluate_gene, group),\n",
        "                            total=len(group),\n",
        "                            desc=\"Evaluating new NNs\",\n",
        "                            leave=False,\n",
        "                            position=0))\n",
        "\n",
        "    def evaluate_population(self):\n",
        "        # Use ProcessPoolExecutor.map, which returns results in order of the input.\n",
        "        with ThreadPoolExecutor(max_workers=12) as executor:\n",
        "        # The executor.map call will preserve order.\n",
        "            self.pop_fitness = list(tqdm(executor.map(self.evaluate_gene, self.population),\n",
        "                                        total=len(self.population),\n",
        "                                        desc=\"Evaluating NNs\",\n",
        "                                        leave=False,\n",
        "                                        position=0))\n"
      ],
      "metadata": {
        "id": "vhflTAu90Hzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Specific code that trains a specific feature combination\n",
        "\"\"\"\n",
        "\n",
        "def parse_gene_str(gene_str):\n",
        "    return [i for i, b in enumerate(gene_str.split()) if b == '1']\n",
        "\n",
        "def train_nn_model(df, selected_features, test_size=0.3, epoch_limit=100, batch_size=1600, learning_rate=0.005):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    X = df[selected_features].to_numpy(dtype=np.float32)\n",
        "    y = df[\"Diabetes_binary\"].to_numpy(dtype=np.float32)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "    X_train_t = torch.tensor(X_train).to(device)\n",
        "    y_train_t = torch.tensor(y_train).unsqueeze(1).to(device)\n",
        "    X_test_t  = torch.tensor(X_test).to(device)\n",
        "    y_test_t  = torch.tensor(y_test).unsqueeze(1).to(device)\n",
        "    train_dl = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(len(selected_features), 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(16, 1)\n",
        "    ).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    for _ in range(epoch_limit):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(\"new epoch\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(model(X_test_t))\n",
        "        preds = (probs > 0.5).float()\n",
        "        acc = (preds == y_test_t).float().mean().item()\n",
        "        auc = roc_auc_score(y_test, probs.cpu().numpy())\n",
        "    return model, {\"accuracy\": acc, \"auc\": auc}\n",
        "\n",
        "def train_from_gene_str(df, gene_str, **kwargs):\n",
        "    feature_cols = [c for c in df.columns if c != \"Diabetes_binary\"]\n",
        "    idxs = parse_gene_str(gene_str)\n",
        "    selected = [feature_cols[i] for i in idxs]\n",
        "    return train_nn_model(df, selected, **kwargs)"
      ],
      "metadata": {
        "id": "UkPHaN_d2LQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}